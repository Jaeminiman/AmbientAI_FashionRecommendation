{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the recommender.pb file to tflite file\n",
    "(For EdgeTPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import tempfile\n",
    "import pathlib\n",
    "import tensorflow_datasets as tfds # for custom dataset\n",
    "%cd ./clothes-detection-yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 17:53:37.825744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 17:53:37.981600: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "resized_img_list = []\n",
    "train_dataset = tfds.load('new_dataset', split = tfds.Split.TRAIN, shuffle_files=True)    \n",
    "x = []\n",
    "for i, data in enumerate(train_dataset):\n",
    "        if(i >=100):\n",
    "                break\n",
    "        emb, label = data['embedding'], data['label']        \n",
    "        x.append(emb.numpy())        \n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양자화를 위해 대표 이미지 생성기를 두어 효과적으로 양자화 되는 것을 tracking 해야 함\n",
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x).batch(1).take(100):\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 200]]\n"
     ]
    }
   ],
   "source": [
    "# For test\n",
    "gen = representative_data_gen\n",
    "\n",
    "\n",
    "for i, sample in enumerate(gen()):\n",
    "  if(i==0):\n",
    "    print([list(s.shape) for s in sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 17:53:38.264975: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-06 17:53:38.264988: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-06 17:53:38.267058: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./weights/recModel\n",
      "2023-03-06 17:53:38.269668: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2023-03-06 17:53:38.269677: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: ./weights/recModel\n",
      "2023-03-06 17:53:38.273408: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-03-06 17:53:38.274723: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-03-06 17:53:38.329976: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./weights/recModel\n",
      "2023-03-06 17:53:38.345577: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 78517 microseconds.\n",
      "2023-03-06 17:53:38.402491: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n"
     ]
    }
   ],
   "source": [
    "# 8bit-integer quantization tflite model\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('./weights/recModel')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error (Full Integer 변환을 위해 operation들이 8bit화를 지원하는지 확인해줌)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8 # or tf.int8\n",
    "converter.inference_output_type = tf.uint8 # or tf.int8\n",
    "\n",
    "post_quant_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 17:53:38.844262: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-03-06 17:53:38.844276: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-03-06 17:53:38.844381: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./weights/recModel\n",
      "2023-03-06 17:53:38.845869: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2023-03-06 17:53:38.845877: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: ./weights/recModel\n",
      "2023-03-06 17:53:38.850414: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-03-06 17:53:38.899079: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./weights/recModel\n",
      "2023-03-06 17:53:38.914412: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 70030 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# float original tflite model convert\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('./weights/recModel')\n",
    "origin_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float tflite model: 0.357 MB\n",
      "quantized tflite model: 0.093 MB\n"
     ]
    }
   ],
   "source": [
    "# create temp file -> 사이즈 측정 용도\n",
    "_, origin_tflite_file = tempfile.mkstemp('.tflite')\n",
    "_, integer_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(origin_tflite_file, 'wb') as f:\n",
    "    f.write(origin_tflite_model)\n",
    "    \n",
    "with open(integer_tflite_file, 'wb') as f:\n",
    "    f.write(post_quant_tflite_model)\n",
    "origin_tflite_size = os.path.getsize(origin_tflite_file) / float(2**20)        \n",
    "integer_tflite_size = os.path.getsize(integer_tflite_file) / float(2**20)        \n",
    "\n",
    "\n",
    "print(f\"Float tflite model: {origin_tflite_size:.03f} MB\")\n",
    "print(f\"quantized tflite model: {integer_tflite_size:.03f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sinjemin/AmbientAI/clothes-detection-yolov5/weights/quantized_model/quantized_recModel.tflite\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "base_path = '/Users/sinjemin/AmbientAI'\n",
    "tflite_models_dir = pathlib.Path(base_path + \"/clothes-detection-yolov5/weights/quantized_model\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"quantized_recModel.tflite\"\n",
    "tflite_model_quant_file.write_bytes(post_quant_tflite_model)\n",
    "print(tflite_model_quant_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'StatefulPartitionedCall:0',\n",
       " 'index': 17,\n",
       " 'shape': array([1, 4], dtype=int32),\n",
       " 'shape_signature': array([-1,  4], dtype=int32),\n",
       " 'dtype': numpy.uint8,\n",
       " 'quantization': (0.00390625, 0),\n",
       " 'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "  'zero_points': array([0], dtype=int32),\n",
       "  'quantized_dimension': 0},\n",
       " 'sparsity_parameters': {}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8bit integer tflite\n",
    "post_quant_interpreter = tf.lite.Interpreter(model_content=post_quant_tflite_model)\n",
    "post_quant_interpreter.allocate_tensors()\n",
    "post_quant_interpreter.get_output_details()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: edgetpu_compiler\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!edgetpu_compiler --min_runtime_version 13 $\"/Users/sinjemin/AmbientAI/clothes-detection-yolov5/weights/quantized_model/quantized_recModel.tflite\" -d "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65530a5f8a55aa4c725f8e525c51b3e477902e1166be13a978af470511979122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
